{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from urllib import request, parse\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "import datetime\n",
    "import ssl\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context  # 全局取消网页安全验证\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.moniter_crowdfunding\n",
    "project = db.projects\n",
    "f_project = db.failure_projects\n",
    "p_founder = db.founders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_proj_craw:\n",
    "\n",
    "    def __init__(self, p_id, count_inqury=0):\n",
    "        self.User_Agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:60.0) Gecko/20100101 Firefox/60.0'\n",
    "        self.Host = 'z.jd.com'\n",
    "        self.p_id = p_id\n",
    "        self.count_inqury = count_inqury  # 访问次数\n",
    "        self.p_d = re.compile('\\d+')\n",
    "        self.craw_time = datetime.datetime.now()\n",
    "        self.category = False\n",
    "\n",
    "        url_1 = 'http://z.jd.com/project/details/%s.html' % self.p_id\n",
    "        req_1 = request.Request(url_1)\n",
    "        req_1.add_header('User-Agent', self.User_Agent)\n",
    "        req_1.add_header('Host', self.Host)\n",
    "        with request.urlopen(req_1) as f_1:\n",
    "            self.isDirected = self.p_id in f_1.geturl()  # 如果p_id不在实际url中，则说明发生了重定向，项目失败\n",
    "            if self.isDirected:  \n",
    "                rawhtml = f_1.read().decode('utf-8')\n",
    "                self.h_soup = BeautifulSoup(rawhtml, 'html.parser')\n",
    "                cat_div = self.h_soup.find('div', {'class': 'project-img'})\n",
    "                l_cat = cat_div.i['class'][0]\n",
    "                if l_cat == 'zc-orange-preheat':  # 预热中、众筹中、众筹成功、项目成功\n",
    "                    self.category = '预热中'\n",
    "                elif l_cat == 'zc-green-ing':\n",
    "                    self.category = '众筹中'\n",
    "                elif l_cat == 'zc-success':\n",
    "                    self.category = '众筹成功'\n",
    "                elif l_cat == 'xm-success':\n",
    "                    self.category = '项目成功'\n",
    "\n",
    "                url_2 = 'http://sq.jr.jd.com/cm/getCount?'\n",
    "                req_2 = request.Request(url_2)\n",
    "                req_2.add_header('User-Agent', self.User_Agent)\n",
    "                req_2.add_header('Referer', 'http://z.jd.com/project/details/%s.html' % self.p_id)\n",
    "                req_2.add_header('Host', self.Host)\n",
    "                post_list = [('_', '15242091922'),\n",
    "                             ('callback', 'jQuery183000564758012421237_1524209188840'),\n",
    "                             ('key', '1000'),\n",
    "                             ('pin', ''),\n",
    "                             ('systemId', self.p_id),\n",
    "                             ('temp', '0.29549820811900180')]  # 关键在于systemID，即项目编号\n",
    "                post_data = parse.urlencode(post_list)\n",
    "                with request.urlopen(req_2, data=post_data.encode('utf-8')) as f_2:\n",
    "                    self.j_soup = f_2.read().decode()\n",
    "\n",
    "    def basic_data(self):\n",
    "        # (1)项目信息\n",
    "        div1 = self.h_soup.find_all('div', {'class': 'project-introduce'})[0]\n",
    "        proj_name = div1.find_all('h1', {'class': 'p-title'})[0].string  # 项目名称\n",
    "\n",
    "        div1_2 = div1.find_all('p', {'class': \"p-target\"})[0]\n",
    "        time_span = div1_2.find_all('span', {'class': 'f_red'})[0].string.strip()  # 提取截止日期\n",
    "        # time_span = int(time_span)\n",
    "        target_fund = div1_2.find_all('span', {'class': 'f_red'})[1].get_text()[1:]  # 目标金额\n",
    "\n",
    "        s = self.h_soup.find_all('div', {'class': \"tab-share-l\"})\n",
    "        sort_name = s[0].a['data-attr']  # 项目所属类别\n",
    "\n",
    "        # (2)发起人信息\n",
    "        div2 = self.h_soup.find_all('div', {'class': \"promoters-name\"})[0]\n",
    "        prom_href = div2.find_all('a')[0]['href']  # 发起人href\n",
    "        prom_name = div2.find_all('a')[0]['title']  # 发起人名称\n",
    "\n",
    "        # (3)公司信息\n",
    "        company_name, company_address, company_phone, company_hours = None, None, None, None  # 先设为None\n",
    "        try:\n",
    "            div3 = self.h_soup.find_all('ul', {'class': \"contact-box\"})[0]\n",
    "            div3_li = div3.find_all('li')\n",
    "            for li in div3_li:  # 少数项目没有公司名称和联系地址\n",
    "                key = li.find('div', {'class': \"key\"}).contents[1]\n",
    "                val = li.find('div', {'class': \"val\"}).string\n",
    "                if key == '公司名称：':\n",
    "                    company_name = val  # 公司名称\n",
    "                elif key == '联系地址：':\n",
    "                    company_address = val  # 联系地址\n",
    "                elif key == '官方电话：':\n",
    "                    company_phone = val  # 官方电话\n",
    "                elif key == '工作时间：':\n",
    "                    company_hours = val  # 工作时间\n",
    "        except IndexError:\n",
    "            print('No company info')\n",
    "\n",
    "        # (4)各档支持信息\n",
    "        div4 = self.h_soup.find_all('div', {'class': \"box-grade \"})\n",
    "        indiv_info = {}\n",
    "        for i, d in enumerate(div4):\n",
    "            sup_price = d.find_all('div', {'class': \"t-price\"})[0].span.string.strip()  # 支持价位\n",
    "            d_1 = d.find_all('div', {'class': \"box-content\"})\n",
    "            lim_num = d_1[0].find_all('span', {'class': \"limit-num\"})[0].string  # 限制人数\n",
    "            redound_info = d_1[0].find_all('p', {'class': \"box-intro\"})[0].string.strip()  # 回报内容\n",
    "            deliver_info = d_1[0].find_all('p', {'class': \"box-item\"})[1].get_text()  # 发货时间\n",
    "            indiv_info[str(i)] = {'sup_price': int(sup_price),\n",
    "                                  'lim_num': lim_num,\n",
    "                                  'redound_info': redound_info,\n",
    "                                  'deliver_info': deliver_info}\n",
    "\n",
    "        return {'项目名称': proj_name, '目标金额': int(target_fund), '众筹期限': time_span,\n",
    "                '所属类别': sort_name, '发起人链接': prom_href, '发起人名称': prom_name,\n",
    "                '公司名称': company_name, '公司地址': company_address, '公司工作时间': company_hours,\n",
    "                '公司电话': company_phone, '各档基础信息': indiv_info}\n",
    "\n",
    "    def update_data(self):\n",
    "        # 当前筹集金额、当前进度、当前支持人数\n",
    "        div1 = self.h_soup.find_all('div', {'class': 'project-introduce'})[0]\n",
    "        try:\n",
    "            div1_1 = div1.find_all('p', {'class': \"p-progress\"})[0]\n",
    "            now_percent = div1_1.find_all('span', {'class': \"fl percent\"})[0].string[4:-1]  # 当前进度\n",
    "            now_supporters = div1_1.find_all('span', {'class': \"fr\"})[0].string[:-4]  # 当前支持人数\n",
    "            now_fund = div1.find_all('p', {'class': \"p-num\"})[0].get_text()[1:]  # 当前项目筹集金额\n",
    "        except IndexError:\n",
    "            now_percent, now_supporters, now_fund = 0, 0, 0\n",
    "            print('  项目还未开始众筹！')\n",
    "\n",
    "        if self.category == '众筹中':  # 获取end_time以决定何时获取review信息\n",
    "            div1 = self.h_soup.find_all('div', {'class': 'project-introduce'})[0]\n",
    "            div1_2 = div1.find_all('p', {'class': \"p-target\"})[0]\n",
    "            end_time = div1_2.find_all('span', {'class': 'f_red'})[0].string.strip()  # 提取截止日期\n",
    "            end_time = '-'.join(self.p_d.findall(end_time))\n",
    "            self.end_time = datetime.datetime.strptime(end_time, '%Y-%m-%d')  # 转化截止日期为标准格式\n",
    "\n",
    "        # 各档支持信息\n",
    "        div4 = self.h_soup.find_all('div', {'class': \"box-grade \"})\n",
    "        indiv_info = {'爬取时间': self.craw_time}\n",
    "        for i, d in enumerate(div4):\n",
    "            now_num_sup = d.find_all('div', {'class': \"t-people\"})[0].span.string.strip()  # 当前支持人数\n",
    "            indiv_info[str(i)] = {'now_num_sup': int(now_num_sup)}\n",
    "\n",
    "        # 当前点赞人数、当前关注者数、项目创建时间、项目更新时间\n",
    "        p_praise = re.compile('\"praise\":(\\d+)')\n",
    "        p_focus = re.compile('\"focus\":(\\d+)')\n",
    "        p_createTime = re.compile('\"createTime\":\"(\\d+-\\d+-\\d+ \\d+:\\d+:\\d+)\"')\n",
    "        p_updateTime = re.compile('\"updateTime\":\"(\\d+-\\d+-\\d+ \\d+:\\d+:\\d+)\"')\n",
    "\n",
    "        praise = p_praise.findall(self.j_soup)[0]  # 点赞人数\n",
    "        focus = p_focus.findall(self.j_soup)[0]  # 关注人数\n",
    "        try:\n",
    "            createTime = p_createTime.findall(self.j_soup)[0]\n",
    "            createTime = datetime.datetime.strptime(createTime, \"%Y-%m-%d %H:%M:%S\") # 项目创建时间\n",
    "\n",
    "            updateTime = p_updateTime.findall(self.j_soup)[0]  # 项目更新时间\n",
    "            updateTime = datetime.datetime.strptime(updateTime, \"%Y-%m-%d %H:%M:%S\") # 项目创建时间\n",
    "        except IndexError:\n",
    "            createTime = datetime.datetime.now()\n",
    "            updateTime = datetime.datetime.now()\n",
    "            print('本项目还没有任何点赞和关注！')\n",
    "\n",
    "        return {'项目动态信息': {'爬取时间': self.craw_time,\n",
    "                                '筹集金额': int(now_fund),\n",
    "                                '完成百分比': float(now_percent),\n",
    "                                '支持者数': int(now_supporters),\n",
    "                                '点赞数': int(praise),\n",
    "                                '关注数': int(focus),\n",
    "                                '创建时间': createTime,\n",
    "                                '更新时间': updateTime},\n",
    "                 '各档动态信息': indiv_info}\n",
    "\n",
    "    def review_data(self):\n",
    "        url = 'https://sq.jr.jd.com/topic/getTopicList?'\n",
    "        req = request.Request(url)\n",
    "        req.add_header('User-Agent', self.User_Agent)\n",
    "        req.add_header('Referer', 'http://z.jd.com/project/details/%s.html' % self.p_id)\n",
    "        req.add_header('Host', 'sq.jr.jd.com')\n",
    "        reviews = {}\n",
    "        i = 1\n",
    "        while True:\n",
    "            post_list = [('_', '1524311286832'),\n",
    "                         ('callback', 'jQuery183036846271396508157_1524311279519'),\n",
    "                         ('key', '1000'),\n",
    "                         ('pageNo', '%d' % i),\n",
    "                         ('pageSize', '20'),\n",
    "                         ('serviceType', '1'),\n",
    "                         ('sort', '1'),\n",
    "                         ('systemId', '%s' % self.p_id),\n",
    "                         ('temp', '0.8972247674942638')] # 关键在于systemID，即项目编号\n",
    "            post_data = parse.urlencode(post_list)\n",
    "            f = request.urlopen(req, data=post_data.encode('utf-8'))\n",
    "            x = f.read().decode()\n",
    "            json_x = json.loads(x[x.find('{\"listResult\"'):-1])\n",
    "            pageBean = json_x['pageBean']\n",
    "            totalPage = int(pageBean['totalPage'])  # 总页数\n",
    "            totalRecord = int(pageBean['totalRecord'])  # 总记录数\n",
    "            # 评论id, 创建时间，点赞数，回复数，内容\n",
    "            for record in json_x['listResult']:\n",
    "                reviews[str(record['topicId'])] = record  # 与原有数据库中不同，保留所有的评论详细信息\n",
    "                \n",
    "            if totalPage > i:\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return {'爬取时间': self.craw_time, '总页数': totalPage, '总评论数': totalRecord, '评论详细': reviews}\n",
    "\n",
    "    def start_craw(self):\n",
    "        x = self.basic_data()\n",
    "        y = self.update_data()\n",
    "        z = self.review_data()\n",
    "        x.update(y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评论中未包含评论详细信息，因此重新爬取评论数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.find_one({'状态': '众筹成功'})['评论']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "ids = [x['_id'] for x in project.find({'状态': {'$in': ['众筹成功', '项目成功']}}, projection={'_id':1})]\n",
    "print(f\"一共{len(ids)}个文档需要更新\")\n",
    "t1 = time.process_time()\n",
    "for p_id in ids:\n",
    "    time.sleep(random.random())\n",
    "    single_craw = Single_proj_craw(p_id)\n",
    "    if i % 30 != 0:\n",
    "        print(f\"{i:3}\", end=' ')\n",
    "    else:\n",
    "        print(f\"{i:3}\")\n",
    "    try:\n",
    "        x = single_craw.review_data()\n",
    "        project.update_one({'_id':p_id}, {'$set': {'评论': x}}, upsert=True)\n",
    "    except Exception as e:\n",
    "        print(p_id, '出错!')\n",
    "    i += 1\n",
    "    \n",
    "print(f'一共用时{(time.process_time() - t1)/60 : .2f}分钟')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先查看p_id是否在数据库中，如果在则直接获取数据；如果不在，则爬取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['项目名称', '目标金额', '众筹期限', '所属类别', '发起人链接', \n",
    "             '发起人名称', '公司名称', '公司地址', '公司工作时间', '公司电话', \n",
    "             '项目动态信息', '评论']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkOtherCols():\n",
    "        suc_ids = list(set(x['_id'] for x in project.find({}, projection={'_id':1})))  # 除失败项目之外的所有项目信息\n",
    "        for p_id in suc_ids[::-1]:  # 有部分文档以ObjectId作为_id\n",
    "            if isinstance(p_id, ObjectId):\n",
    "                print(f\"success {p_id}\")\n",
    "                t_id = project.find_one({\"_id\":p_id}, projection={'项目编号':1})\n",
    "                suc_ids.remove(p_id)\n",
    "                suc_ids.append(t_id['项目编号'])\n",
    "        \n",
    "        fail_ids = list(set(x['详细信息']['_id'] for x in f_project.find({}, projection={'详细信息._id':1})))\n",
    "        for p_id in fail_ids[::-1]:  # 将_id为ObjectID类型的替换为项目编号\n",
    "            if isinstance(p_id, ObjectId):\n",
    "                print(f\"failure {p_id}\")\n",
    "                t_id = f_project.find_one({\"详细信息._id\":p_id}, projection={\"详细信息.项目编号\":1})\n",
    "                fail_ids.remove(p_id)\n",
    "                fail_ids.append(t_id[\"详细信息\"][\"项目编号\"])\n",
    "                \n",
    "        return set(suc_ids) | set(fail_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_ids = checkOtherCols()\n",
    "ids = [x['_id'] for x in p_founder.find({}, projection={'_id':1})]\n",
    "fail_list = []\n",
    "i = 1\n",
    "t1 = time.process_time()\n",
    "for p_id in ids:\n",
    "    if p_id in exist_ids:\n",
    "        info_dict = project.find_one({'_id':p_id}, projection={x:1 for x in col_list})\n",
    "        if not info_dict:\n",
    "            temp = f_project.find_one({'项目编号':p_id}, projection={'详细信息':1})\n",
    "            info_dict = {x:temp['详细信息'][x] for x in temp['详细信息'] if x in col_list}\n",
    "        \n",
    "        if i % 10 != 0:\n",
    "            print(f\"{p_id:5} m\", end='  ')\n",
    "        else:\n",
    "            print(f\"{p_id:5} m\")\n",
    "    else:\n",
    "        try:\n",
    "            single_craw = Single_proj_craw(p_id)\n",
    "            temp = single_craw.start_craw()\n",
    "            info_dict = dict([x for x in temp.items() if x[0] in col_list])\n",
    "        except Exception as e:\n",
    "            info_dict = {}\n",
    "        \n",
    "        if i % 10 != 0:\n",
    "            print(f\"{p_id:5} c\", end='  ')\n",
    "        else:\n",
    "            print(f\"{p_id:5} c\")\n",
    "    try:\n",
    "        p_founder.update_one({'_id':p_id}, {'$set':info_dict}, upsert=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fail_list.append(p_id)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "print(f'一共用时{(time.process_time() - t1)/60 : .2f}分钟！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = f_project.find_one({'项目编号':'105325'}, projection={'详细信息':1})\n",
    "if temp:\n",
    "    info_dict = {x:temp['详细信息'][x] for x in temp['详细信息'] if x in col_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_craw = Single_proj_craw('101120')\n",
    "x = single_craw.start_craw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['评论详细']['1951617']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "78321 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "help(np.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('fail_list', fail_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
